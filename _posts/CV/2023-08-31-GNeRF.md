---

title:  "[Paper Review] GNeRF: GAN-based Neural Radiance Field without Posed Camera"

excerpt: "GNeRF 논문 리뷰"
categories:
  - CV
use_math: true
toc_label: "  목차"
toc: true
toc_sticky: true

---
# Intro

- 카메라 포즈를 추정하는 것은 매우 어려운 과제이다.
    - 기존의 카메라 포즈 추정은 반복되는 패턴, 다양한 조도(varying light), keypoint가 적은 scene 등에서 포즈 추정에 있어서 어려움을 겪으며, 이는 NeRF 모델의 한계점이다.
- 카메라 포즈 정보에 대한 모델의 의존성을 완화시키기 위하여 최근 iNeRF와 NeRF--는 훈련 과정에서 다른 parameter를 포함하여 카메라 포즈를 최적화하려는 시도를 하였다.
    - 그러나 NeRF--는 forward-facing scenes로 제한되며,
    - iNeRF는 neural radiance field 추정이 아닌 카메라 포즈 추정에 초점이 맞추어져 있다.
- 본 논문에서는 카메라가 complex scenarios에서 임의로 초기화 되었을 때 카메라 포즈와 neural radiance field를 모두 추정가능한 GNeRF를 제안한다.
    - GNeRF는 먼저 adversarial training을 통해 coarse 카메라 포즈와 radiance fields를 얻고, 다음으로 photometric loss를 사용해 이를 개선한다.

# Preliminary

## Camera Pose

- 공식적으로는 3D 공간에서의 카메라 position/location과 canonical view에서의 rotation을 기반으로 카메라 포즈/외부 파라미터를 표현한다.
- 카메라 위치는 유클리디안 공간에서의 3d embedding 벡터로 표현한다.
- 카메라 회전과 관련하여 많이 쓰이는 quaternions과 euler angle은 학습하기 어렵다. 따라서 6d embedding 벡터를 사용하여 3d rotation을 표현한다.
    - 3x3의 회전 행렬이 주어지면 마지막 행을 제거하여 회전 벡터 r을 계산한다.
    - gram-schmidt와 유사한 방법을 통해 6d 포즈 임베딩 벡터에서 원래의 회전 행렬을 복구할수도 있다.
    - (Yi Zhou, Connelly Barnes, Jingwan Lu, Jimei Yang, and Hao Li. On the continuity of rotation representations in neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019)

## NeRF Scene Representation

- GNeRF는 3d scene과 image formation을 표현하기 위해 NeRF 프레임워크를 채택하였다.
- $\mathcal I$는 single scene에 대한 RGB 이미지, $\Phi$는 그에 각 맞는 카메라 포즈, $G$는 미분가능한 볼륨 렌더러를 각각 의미하고, 이에 대해 아래의 loss를 사용하여 NeRF는 continuous volumetric scene function을 최적화 한다.
    
    $$\mathcal L_N(\Theta,\Phi)={1\over n}\sum_{i=1}^n\lVert I_i-\hat I_i \rVert_2^2, \ \ \hat I_i=G(\phi_i;F_{\Theta})$$
    
    

# Method

<p align="center">
  <img src="/images/gnerf_1.png">
</p>

## Pose-free NeRF Estimation

- 논문에서 소개되는 방식의 첫번째 단계에서는 각 이미지에 대한 대략적인 포즈를 예측하고 scene의 대략적인 radiance field 학습을 진행하는 것이 목표이다. 그림에서 볼 수 있듯이, 목표 달성을 위해 adversarial learning을 사용한다.
- 아키텍쳐는 제너레이터 $G$와 판별자 $D$ 두 부분으로 구성된다.
    - 제너레이터 $G$는 임의의 카메라 포즈 $\phi$를 입력으로 받아 nueral radiance field를 query하고 NeRF와 유사한 볼륨 렌더링을 수행하여 뷰에서 관찰된 이미지를 합성한다.
    - 샘플링된 여러 카메라 포즈에서 합성된 이미지 세트는 패치로 분해되어 판별자 $D$에 의해 real 패치 세트와 비교된다.
    - fake 패치와 real 패치는 이후 설명할 dynamic patch sampling strategy를 통해 샘플링된다.
- 훈련세트 $\mathcal I$의 real 이미지 패치 $P_d(I)$와 fake 이미지 패치 $P_d(I\vert \theta)$ 사이의 분포거리를 최소화하고자 하고 이는 아래 수식과 같이 정의 된다.
    
    $$\Theta^*=\arg \min_\Theta Dist(P_g(I|\Theta) \Vert P_d(I))$$
    $$ P_g(I|\Theta)=\int_\theta G(\phi ; F_\Theta)P(\phi) d\phi$$
    
- 분포 거리를 최소화 하기 위해, 아래와 같은 adversarial Loss를 사용하였고, 식의 $\eta$는 판별자 $D$의 네트워크 파라미터를 의미한다.
    
    $$\min_\Theta \max_\eta \mathcal L_A(\Theta, \eta) = \mathbb E_{I\sim P_d}[\log (D(I;\eta))] + \mathbb E_{\hat I \sim P_g}[\log (1-D(\hat I ; \eta))]$$
    
    
- 랜덤하게 샘플링된 카메라 포즈와 생성된 이미지 패치 쌍의 Loss function은 아래와 같다.
    
    $$\mathcal L_E(\theta_E)= \mathbb E_{\phi \sim P(\phi)}[\Vert E(G_\phi;F_\Theta);\theta_E)-\phi\Vert_2^2]$$ 
    
- inversion network $E$는 점점 더 잘 훈련된 제너레이터 $G$를 통해 real 이미지 패치에 대한 카메라 포즈를 예측할 수 있게 된다.
- 훈련 후 훈련세트 $\mathcal I$에 대해 inversion network $E$를 적용하여 카메라 포즈 $\phi'$를 생성한다.

## Regularized Learning Strategy

- 위 단계를 통해서 훈련세트에 대한 initial NeRF 모델과 카메라 포즈 추정치를 얻게 된다.
- 입력 이미지 패치에 대한 sparse sampling과 inversion network E에 대한 constrained capability에 의해 NeRF 모델과 카메라 포즈 추정치 모두 사용하기에 충분히 정확하지 않다.
- 그러나 전체 훈련 과정에서 좋은 initialization을 제공하며, 이는 위 그림에서 볼 수 있듯 다음 단계(Phase B)로 NeRF 모델과 카메라 포즈에 대한 개선 단계를 진행할 수 있게 해준다.
- 구체적으로 이 단계는 아래 Loss를 최소화하여 NeRF 모델과 포즈 임베딩을 최적화한다.
    
    $$\mathcal L_N(\Theta,\Phi)={1\over n}\sum_{i=1}^n\lVert I_i-\hat I_i \rVert_2^2, \ \ \hat I_i=G(\phi_i;F_{\Theta})$$
    
    
- 이렇듯 본 논문에서는 포즈가 필요없는 NeRF 추정 단계 (Phase A), NeRF 개선 단계 (Phase B)가 혼합된 학습 전략(AB...AB)을 제안하여 NeRF 모델과 포즈 추정의 품질을 향상시킨다.
    - 이 학습전략은 학습된 inversion network를 통한 포즈 예측을 통해 descent-based model optimization을 정규화한다.
- photomatic reconstruction error와 L2 Loss를 결합한 $\mathcal L_R$을 정의하여 사용한다. 여기서 $\lambda$는 weighting coefficient이다.
    
    $$\mathcal L_R(\Theta, \Phi)=\mathcal L_N(\Theta, \Phi) + {\lambda \over n} \sum_{i=1}^n \Vert E(I+i; \theta_E)-\phi_i \Vert_2^2$$
        
    

## Training

- 처음에는 카메라 extrinsics를 identity 행렬로 설정한다.
- Phase A에서는, 이전 포즈 분포로부터 카메라 포즈 $\phi$가 랜덤하게 샘플링된다.
- generative radiance field를 학습하기 위해 GRAF와 같은 similar patch sampling strategy를 따른다.
    - GAN training 과정에서는 dynamic patch sampling strategy를 따른다.
    - (공부 후 추가 예정)
- 또한 처음에 카메라 intrinsics를 조정하여 receptive field를 최대화하고 점점 original value로 늘려 미세한 디테일에 집중하도록 한다.

## Implementation Details

- coarse sampling과 importance sampling의 샘플링 포인트 수는 모두 64개를 사용한다.
- GAN의 훈련은 real 패치와 fake 패치 (coarse and fine)의 분포를 좁히기 때문에 hierachical 샘플링 전략에서 동일한 MLP를 사용한다.
    - 전체 파라미터가 변하지 않도록 하기 위해 MLP의 차원을 256에서 360으로 늘렸다.
- inversion network의 경우 ViT를 차용하여 구축하였으며, 마지막 레이어는 카메라 포즈를 출력하도록 수정되었다.
- RMS prop을 사용하여 제너레이터 $G$와 판별자 $D$를 최적화하였으며 각 lr은 0.0005, 0.0001로 설정하였다.
- inversion network와 카메라 포즈는 lr이 0.0001과 0.005인 Adam 알고리즘을 사용하였다.

# Experiments

<p align="center">
  <img src="/images/gnerf_2.png">
</p>

<p align="center">
  <img src="/images/gnerf_3.png">
</p>

- 표를 통해 COLMAP 기반의 NeRF와 동등한 수준의 새로운 뷰를 생성하는 것을 확인할 수 있다. 또한 Scan 47, Scan 104와 같은 challenging scene에서는 훨씬 좋은 결과를 내고 있음을 확인할 수 있다.
    - 이 때 COLMAP은 더 많은 입력 이미지로 더 정확한 포즈 추정을 생성하므로 공정한 평가를 위해 제한된 수의 테스트 이미지만 선택하였다.

<p align="center">
  <img src="/images/gnerf_4.png">
</p>

- IDR 방식과 렌더링 품질을 비교하였을 때도 볼륨 렌더링 기반 방식이 더 좋은 결과를 내고 있음을 확인할 수 있다.
