---

title:  "[Paper Review] Generative Adversarial Networks"

excerpt: "GAN 논문 리뷰"
categories:
  - CV
toc_label: "  목차"
toc: true
toc_sticky: true

date: 2023-05-25
last_modified_at: 2023-05-25
---

## Background

딥러닝 분야에서는 다양한 연구들이 진행되며 특히 데이터를 분류하는 $discriminative$ $model$에서 비약적인 성장이 이루어지고 있다. 하지만, 딥러닝 모델을 통해 데이터를 생성하는 $Deep$ $generative$ $model$ 분야에서는 다양한 확률적 계산 이슈에 가로막혀 큰 성장을 이루지 못하고 있는 상황이다. 본 논문에서는 이러한 문제들을 극복한 새로운 $generative$ $model$ $framework$를 제안하였다.

해당 $framework$는 두 개의 모델이 $adversarial(적대적)$로 동작하며 학습을 진행한다.

첫 번째 모델은 $discriminative$ $model$이다. $discriminative$ $model$은 특정 데이터가 주어졌을 때, 해당 데이터가 진짜인지 가짜인지 분류$(classify)$하는 기능을 수행한다. 두 번째 모델은 $generative$ $model$이다. $generative$ $model$은 데이터를 생성하는 모델로, 최대한 실제 데이터와 유사하게 만들어내는 것이 목표이다. 본 논문에서는 이 두 모델, $discriminative$ $model$과 $generative$ $model$을 각각 경찰과 지폐 위조범에 비유하여 설명하였다. 경찰, 즉 $discriminative$ $model$은 최대한 실제 돈$(real$ $data)$과 가짜 돈$(fake$ $data)$을 구분하도록 학습이 진행되며, 지폐 위조범, 즉 $generative$ $model$은 최대한 실제 돈$(real$ $data)$과 비슷한 가짜 돈$(fake$ $data)$을 생성하도록 학습이 진행된다.

이렇게 두 개의 모델이 대립적으로 동작하며 각자의 목표에 맞춰 학습을 진행하는 모델이 바로 $adversarial$ $nets$이다.

## Adversarial nets

$generative$ $model$의 목표는 확률분포 $P_g$가 실제 데이터 $x$의 확률분포를 닮도록 만드는 것이다. 이를 위해 $generative$ $model$이 초기에 사용하는 $noise$ $variables$ $z$의 확률분포 $P_z(z)$를 정의하였다고 하자.

이때, 본 논문에서 제안하는 $adversarial$ $network$의 $objective$ $function(손실$ $함수)$은 아래와 같다.

$$
\min_{G}\max_{D}V(D,G) = E_{x \sim p_{data}}[\log D(x)] + E_{z \sim p_{z}(z)}[\log(1-D(G(z)))]
$$

우선 함수 $V$는 $D$와 $G$ 두 개의 변수를 가지고 있다. 하지만, $G$는 $V$ 함수값을 최대한 작게 만들려는 변수이며, $D$는 $V$ 함수값을 최대한 크게 만들려는 변수이다. 즉, 함수 $V$에 대한 $G$와 $D$의 $min-max$ 게임이라고 볼 수 있다.

등호의 오른쪽을 살펴보면 크게 좌변과 우변을 더하는 식으로 구성되어 있다.

좌변은 실제 데이터 $x$에 대하여 $\log D(x)$ 값의 기댓값을 나타내는 식이다.

$Discriminator$ $D$는 $x$의 값이 실제 존재하는 데이터라고 판단될 경우 $1$을, 가짜 데이터라고 판단될 경우 $0$을 반환한다. 만약 $x$가 실제 데이터일 경우, $D(x)$는 올바르게 판단할 경우 $1$을 반환할 것이다. 따라서 $D$의 성능이 좋을수록 좌변의 값은 증가하게 될 것이다.

우변은 가짜 데이터 $z$에 대하여 $\log(1-D(G(z)))$ 값의 기댓값을 나타내는 식이다.

$Generator$ $G$는 $latent$ $vector$ $z$를 입력받아 가짜 데이터를 생성하는 기능을 수행한다. 이렇게 생성된 가짜 데이터는 $D$를 통해 진짜인지 아닌지 판단된다.

만약 $Generator$의 성능이 훌륭하여 $D$가 가짜 데이터를 진짜 데이터라고 오판할 경우, $D(G(z))$의 값이 $1$이 될 것이며, $1-D(G(z))$의 값은 $0$이 된다.

즉, 전체적으로 점검해보면, $Discriminator$ $D$는 $objective$ $function$의 값을 최대한 키우도록 학습을 진행할 것이고, $Generator$ $G$는 $objective$ $function$의 값을 최대한 작게 줄이도록 학습을 진행할 것이다.

이것이 바로 $GAN$의 기본적인 작동 원리이다.

<p style="text-align: center;">
  <img src="/images/gan1.png" width="100%">
</p>

$Figure$ $1$에서 아래쪽에 위치한 화살표는 $Z$ 공간에서 뽑은 확률변수들을 $X$ 공간에 매핑한 것을 의미한다.

$(a)$나 $(b)$ 그림을 보면 알 수 있듯이, 이렇게 매핑된 확률변수들은 실제 데이터인 검은색 점과는 다른 초록색의 확률 분포를 가지게 된다. 이렇게 될 경우, 파란색 점선으로 표현된 $discriminator$ $model$의 분포 역시, 두 데이터를 명확하게 분별할 수 있는 모습을 가지게 된다.

하지만 학습 과정을 거치면서, $Z$와 $X$의 확률분포가 유사한 모습을 가지게 된다면, $(c)$, $(d)$ 그림과 같이 실제 데이터와 가짜 데이터의 확률 분포가 일치하게 학습되며, $discriminator$ $model$의 분포를 보았을 때 두 데이터를 분별하지 못하는 것을 확인할 수 있다.

<p style="text-align: center;">
  <img src="/images/gan2.png" width="80%">
</p>

$Figure$ $2$는 논문에서 제안하는 핵심 알고리즘이다.

우선 첫 번째 $for$ 문을 통해 $epoch$ 수를 설정한다. 이후 두 번째 $for$ 문을 통해 $k$번 동안 $Discriminator$를 학습한다.

$Discriminator$를 학습하는 방법은, $m$개의 가짜 데이터와 $m$개의 실제 데이터를 뽑아 $objective$ $function$에 대입하여 계산한 뒤, $objective$ $function$의 함수값이 커지는 방향으로 $gradient$ $descent$ 과정을 거치며 학습해 나간다.

$k$번 동안 $Discriminator$를 학습하는 과정이 끝나면, $Generator$를 학습하는 과정을 거친다.

$Generator$를 학습하는 방법은, $m$개의 가짜 데이터를 뽑아 $objective$ $function$에 대입하여 계산한 뒤, $objective$ $function$의 함수값이 작아지는 방향으로 $gradient$ $descent$ 과정을 거치며 학습해 나간다. 물론 $objective$ $function$의 좌변에는 $z$ 변수가 포함되지 않으므로, 미분하는 과정에서 좌변은 사라지게 된다.

위 과정을 $epoch$ 수만큼 반복하며 $Generator$와 $Discriminator$를 학습하게 되고, 그 결과 $P_g = P_{data}$의 분포를 가지게 된다.

## Theoretical Results

먼저 주어진 생성자 $G$를 위한 최적의 판별자 $D$를 고려한다. $G$가 고정되었을 때, 최적의 판별자 $D$는 다음과 같다.

$$
D^*_G(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}
$$

이를 $objective$ $function$에 대입해보면 아래와 같다.

$$
V(G,D) = \int_x p_{data}(x)\log(D(x))dx + \int_z p_z(z)\log(1-D(g(z)))dx \\
= \int_x p_{data}(x)\log(D(x)) + p_g(x)\log(1-D(x))dx
$$

수식을 보면, $a\log(y) + b\log(1-y)$의 꼴로 정리할 수 있으며, 이 함수의 최대값이 되는 $y$값은 $\frac{a}{a+b}$이기 때문에 위의 식 같은 $optimal$ $D$에 관한 함수값을 구할 수 있는 것이다.

다음으로 $D$가 $optimal$한 지점을 가질 때의 $V$ 함수를 $C(G)$로 표현할 수 있으며, 이때의 식은 아래와 같다.

$$
C(G) = \max_D V(G,D) = E_{x\sim p_{data}}[\log D^G(x)] + E_{z \sim p_z}[\log(1 - D^G(G(z)))] \\
= E_{x\sim p_{data}}[\log D^G(x)] + E_{z \sim p_z}[\log(1 - D^G(x))] \\
= E_{x\sim p_{data}}\left[\log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\right] + E_{x\sim p_g}\left[\log \frac{p_g(x)}{p_{data}(x) + p_g(x)}\right]
$$

위 식의 경우 $P_{data}=P_G$인 경우 $-\log 4$의 최솟값을 갖는다. 해당 기댓값 공식을 $KL$ $divergence$ 값으로 정리해보면 아래와 같다.

$$
C(G) =-\log(4) + KL(p_{data} \parallel \frac{p_{data} + p_g}{2}) + KL(p_g \parallel \frac{p_{data} + p_g}{2})
$$

이를 다시 $JSD$ $divergence$로 나타내면 아래와 같다.

$$
C(G)=-\log(4) + 2 \cdot JSD (p_{data} \parallel p_g)
$$

따라서 결과적으로 $P_{data}=P_g$인 경우 $global$ $optimal$에 도달할 수 있음을 알 수 있다.

## Experiments

<p style="text-align: center;">
  <img src="/images/gan3.png" width="90%">
</p>

$Figure$ $3$에서 볼 수 있듯이, 본 논문에서 제안된 $GAN$ 모델을 활용하여 $MNIST$ / $Toronto$ $Face$ $Database$에 적용했을 때, 다른 $generative$ $model$에 비해 높은 성능을 보이는 것을 확인할 수 있다.

<p style="text-align: center;">
  <img src="/images/gan4.png" width="100%">
</p>

$Figure$ $4$는 실제 $GAN$ 모델을 통해 생성한 이미지 데이터를 나타낸다. 오른쪽 노란색 박스들은 실제 데이터이며, 노란색 박스 왼쪽의 데이터들은 $GAN$을 통해 생성한 데이터이다. 이를 통해 실제 데이터와 $GAN$이 생성한 데이터 간 차이가 크지 않음을 알 수 있고, 동시에 실제 데이터와 생성한 데이터가 일치하지 않는 것을 확인할 수 있다. 이는 $GAN$ $network$가 단순히 입력 데이터를 복사하는 것이 아니라 스스로 새로운 데이터를 생성한다는 것을 의미한다.

## Advantages and Disadvantages

$GAN$ $framework$는 복잡한 기술이 필요하지 않고, 다른 $generative$ $model$에 비해 성능이 높다는 장점이 있다. 또한 데이터에 의해 $generator$가 직접 학습되지 않고, $discriminator$를 통해 간접적으로 학습되므로, 데이터의 $components$들이 직접적으로 복사되지 않아 다양하고 고품질의 데이터를 생성할 수 있으며 생성된 이미지 데이터가 $blurry$하지 않고 $sharp$하게 표현된다는 점이 장점이다.

반면 $P_g(x)$를 나타내는 명시적인 표현방법이 존재하지 않고, $D$와 $G$는 학습하는 동안 완벽하게 동기화$(synchronized)$되어야 한다는 점이 단점이다.

## Conclusion and Future Work

이 $framework$는 많은 간단한 확장을 허용한다.

1. $Conditional$ $generative$ $model$ $p(x∣c)$는 $G$와 $D$ 둘 다에 $c$를 추가함으로써 얻어질 수 있다.
2. 대략적인 추론 학습은 $x$가 주어졌을 때 $z$를 예측하기 위해 $auxiliary$ $network$를 학습함으로써 수행될 수 있다. 이것은 $wake-sleep$ $algorithm$에 의해 학습된 추론 네트워크와 비슷하지만, 추론 네트워크가 생성자 네트워크의 학습이 끝난 후 고정된 생성자를 위해 학습된다는 장점이 있다.
3. 모든 조건부 확률 $p(x_s∣x_{\not s})$를 대략적으로 모델링할 수 있다. $S$는 파라미터를 공유하는 조건부 모델의 집합을 학습에 의한 $x$ 인덱스의 하위 집합이다. 본질적으로, $adversarial$ $nets$를 사용하여 결정론적 $MP-DBM$의 확률적 확장을 구현할 수 있다.
4. $Semi-supervised$ $learning$: 판별자 혹은 추론 네트워크로부터 나온 $feature$는 제한된 라벨 데이터가 있을 때 분류기의 성능을 향상시킬 수 있다.
5. $Efficiency$ $improvements$: 학습은 $G$와 $D$를 조정하는 방법을 나누거나 학습 동안 $z$를 샘플링하기 위한 더 좋은 분포를 결정하는 것에 의해 가속화될 수 있다.

본 논문은 적대적 모델링 $framework$의 실행 가능성을 입증하여 이러한 연구 방향이 유용할 수 있음을 시사한다.
